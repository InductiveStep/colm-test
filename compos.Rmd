---
title: "Did turnout predict the composition of Labour, Tory, and Reform votes in the 2024 UK general election?"
author: "Andi Fugard (@andi@sciences.social)"
date: 10 July 2024
output:
  html_document:
    df_print: paged
  html_notebook:
    code_folding: none
---

```{r}
#devtools::install_github("DavidFirth/compos")
library(conflicted)
library(tidyverse)
library(compos)
library(ggmice)
library(mice)
```


The data used below was collated and published by [Democracy Club](https://candidates.democracyclub.org.uk/data/?election_id=parl.2024-07-04&field_group=results) under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). I manually updated results for Edinburgh North and Leith since (on 9 July 2024) the turnout and total electorate values were mixed up (turnout percentage would have been over 100%, though was capped at 100%). This has now (10 July) been fixed in the original. The House of Commons Library is due to publish its own voting dataset [here](https://commonslibrary.parliament.uk/research-briefings/cbp-10009/) around 12 July.


```{r}
ge_dat <- read_csv("uk_general_election_2024.csv")
```


Filter so we only have Labour, Tory, and Reform.

```{r}
parties <- c("Labour and Co-operative Party",
             "Labour Party",
             "Conservative and Unionist Party",
             "Reform UK")
```


And pivot wider, with all the data we want:

```{r}
simp_dat <- ge_dat |>
  dplyr::filter(party_name %in% parties) |>
  mutate(
    part = case_when(
      party_name == "Labour and Co-operative Party" ~ "Lab",
      party_name == "Labour Party" ~ "Lab",
      party_name == "Conservative and Unionist Party" ~ "Con",
      party_name == "Reform UK" ~ "Ref",     
      .default = NA_character_
    )
  ) |>
  select(post_label, part, votes_cast, turnout_percentage) |>
  pivot_wider(names_from = "part", values_from = "votes_cast")
simp_dat
```


```{r}
simp_dat |> summary()
```

```{r}
plot_pattern(simp_dat, rotate = TRUE)
```



What percentage of missing data on turnout?

```{r}
(simp_dat$turnout_percentage |> is.na() |> mean() * 100) |> round(0)
```


Zap all the rows with any missing data (e.g., Reform didn't stand a candidate or no turnout data is available).

```{r}
for_analy_counts <- na.omit(simp_dat)
```

Create another data frame with percentages, conditional on voting for one of these three parties.

```{r}
perc <- for_analy_counts |>
  pivot_longer(names_to = "Party",
               values_to = "Votes",
               cols = Ref:Con) |>
  group_by(post_label) |>
  mutate(Perc = 100 * Votes / sum(Votes))
perc
```


```{r dpi=300}
perc |>
  ggplot(aes(turnout_percentage, Perc, colour = Party)) +
  geom_point(size = .7) +
  geom_smooth(se = FALSE,
              method = "loess",
              formula = y ~ x) +
  labs(
    x = "Turnout (%)",
    y = "Votes (%)",
    title = "UK general election 2024",
    caption = "Percentage votes are conditional on voting Tory, Labour, or Reform"
  ) +
  scale_color_manual(values = c("#0087dc", "#d50000", "#12b6cf"))
```



## Fit the models using the original counts

Now, onto David Firth and Fiona Sammut's model.

These use the default generalized Wedderburn logit model.

```{r}
mod1_count <- colm(cbind(Con, Lab, Ref) ~ turnout_percentage, ref = 1, data = for_analy_counts)
mod2_count <- colm(cbind(Con, Lab, Ref) ~ turnout_percentage, ref = 2, data = for_analy_counts)
mod3_count <- colm(cbind(Con, Lab, Ref) ~ turnout_percentage, ref = 3, data = for_analy_counts)
```


```{r}
short_sum <- function(mod) {
  (mod |> summary())$Coefficients
}
```

```{r}
mod1_count |> short_sum()
mod2_count |> short_sum()
mod3_count |> short_sum()
```

I need to RTFM to work out how to interpret the coefficients; however, the estimates/SE for turnout are over 14 for the comparisons of Labour versus Conservative and Reform versus conservative. They are around 4 for Labour versus Reform.



## Try again with percentages

If I've understood correctly, then using the percentages as outcomes, rather than counts, should give the same results:

```{r}
for_analy_percs <- perc |>
  select(-Votes) |>
  pivot_wider(names_from = "Party",
              values_from = "Perc")
for_analy_percs
```

```{r}
mod1_perc <- colm(cbind(Con, Lab, Ref) ~ turnout_percentage, ref = 1, data = for_analy_percs)
mod2_perc <- colm(cbind(Con, Lab, Ref) ~ turnout_percentage, ref = 2, data = for_analy_percs)
mod3_perc <- colm(cbind(Con, Lab, Ref) ~ turnout_percentage, ref = 3, data = for_analy_percs)
```

Reference level Con:

```{r}
mod1_count |> short_sum()
mod1_perc  |> short_sum()
```

Reference level Lab:

```{r}
mod2_count |> short_sum()
mod2_perc  |> short_sum()
```

Reference level Reform:

```{r}
mod3_count |> short_sum()
mod3_perc  |> short_sum()
```

And indeed they do.


