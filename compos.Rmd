---
title: Was turnout associated with the composition of Labour, Tory, and Reform votes in the 2024 UK general election?
author: "Andi Fugard (Mastodon: @andi@sciences.social)"
date: 31 July 2024
output:
  html_document:
    df_print: paged
  html_notebook:
    code_folding: none
  word_document: default
---

This is an excuse to try out the {compos} package, by David Firth and Fiona Sammut, using [data](https://commonslibrary.parliament.uk/research-briefings/cbp-10009/) from the House of Commons Library, published 18 July.

Load up some packages ({compos} isn't on CRAN yet):

```{r}
#devtools::install_github("DavidFirth/compos")
library(compos)
library(conflicted)
library(tidyverse)
library(ggmice)
library(mice)
library(table1)
library(marginaleffects)
```


## Setup the data

Candidate-level data:

```{r}
ge_dat <- read_csv("HoC-GE2024-results-by-candidate.csv")
```

Constituency-level data, used for the turnout figures:

```{r}
ge_turnout <- read_csv("HoC-GE2024-results-by-constituency.csv") |>
  mutate(turnout_percentage = 100*`Valid votes`/Electorate) |>
  select(`Constituency name`, turnout_percentage) |>
  rename(constituency = `Constituency name`)
ge_turnout
```

Filter so we only have Labour, Tory, and Reform, join on the turnout, and pivot wider with all the data we want (also fix one typo in the data, which I've notified Commons Library about):

```{r}
parties <- c("Lab", "Con", "RUK")

simp_dat <- ge_dat |>
  dplyr::filter(`Party abbreviation` %in% parties) |>
  select(`Constituency name`, `Party abbreviation`, Votes) |>
  mutate(
    `Constituency name` = ifelse(
      `Constituency name` == "YeoYeovil",
      "Yeovil",
      `Constituency name`
    )
  ) |>
  pivot_wider(names_from = `Party abbreviation`, values_from = "Votes") |>
  rename(constituency = `Constituency name`) |>
  left_join(ge_turnout)
simp_dat
```


```{r}
table1( ~ ., data = simp_dat |> dplyr::select(-constituency))
```



Missingness:

```{r}
plot_pattern(simp_dat, rotate = TRUE)
```




```{r}
names(simp_dat)
```

Zap all the rows with any missing data (e.g., because Reform didn't stand a candidate).

```{r}
for_analy_counts <- na.omit(simp_dat)
table1( ~ ., data = for_analy_counts |> dplyr::select(-constituency))
```


Create another dataframe with percentages, conditional on voting for one of these three parties.

```{r}
perc <- for_analy_counts |>
  pivot_longer(names_to = "Party",
               values_to = "Votes",
               cols = Con:Lab) |>
  group_by(constituency) |>
  mutate(Perc = 100 * Votes / sum(Votes))
perc
```

## Have a look

```{r dpi=300}
plot_votes <- perc |>
  ggplot(aes(turnout_percentage, Perc, colour = Party)) +
  geom_point(size = .7) +
  labs(
    x = "Turnout (%)",
    y = "Votes (%)",
    title = "UK general election 2024",
    caption = "Percentage votes are conditional on voting Tory, Labour, or Reform"
  ) +
  scale_color_manual(values = c("#0087dc", "#d50000", "#12b6cf"))
plot_votes +
  geom_smooth(se = FALSE,
              method = "loess",
              formula = y ~ x)
```



## Modelling

### Fit the models using the original counts

Now, onto the modelling. These use the generalized Wedderburn logit model.

```{r}
mod1_count <- colm(cbind(Con, Lab, RUK) ~ turnout_percentage, ref = 1, data = for_analy_counts)
mod2_count <- colm(cbind(Con, Lab, RUK) ~ turnout_percentage, ref = 2, data = for_analy_counts)
mod3_count <- colm(cbind(Con, Lab, RUK) ~ turnout_percentage, ref = 3, data = for_analy_counts)
```


```{r}
short_sum <- function(mod) {
  (mod |> summary())$Coefficients
}
```

```{r}
mod1_count |> short_sum()
mod2_count |> short_sum()
mod3_count |> short_sum()
```

The estimates/SE for turnout are around 20 for the comparisons of Labour versus Conservative and Reform versus conservative. They are around 6 for Labour versus Reform. So, all "statistically significant".

Now the coefficients. Choose the first model:


```{r}
bs <- mod1_count |> coef()
bs
```

These are as easy to interpret as logistic regression coefficients ;-) One trick is to exp them to get odds ratios.

```{r}
bs |> exp() |> round(2)
```

The intercepts give the odds of voting each party rather than Conservative when turnout is zero, which probably isn't useful... Each percentage point increase in turnout reduces the odds of voting Labour by 8% compared to Conservative.

It's easier to plot them:


```{r}
lab_vs_con_pred <- function(t)
  exp(bs["(Intercept)", "Lab"] + bs["turnout_percentage", "Lab"] * t)
ref_vs_con_pred <- function(t)
  exp(bs["(Intercept)", "RUK"] + bs["turnout_percentage", "RUK"] * t)
con_vs_con_pred <- function(t)
  exp(bs["(Intercept)", "Con"] + bs["turnout_percentage", "Con"] * t)

lab_pred <- function(turnout)
  100 * lab_vs_con_pred(turnout) /
  (lab_vs_con_pred(turnout) + con_vs_con_pred(turnout) + ref_vs_con_pred(turnout))
con_pred <- function(turnout)
  100 * con_vs_con_pred(turnout) /
  (lab_vs_con_pred(turnout) + con_vs_con_pred(turnout) + ref_vs_con_pred(turnout))
ref_pred <- function(turnout)
  100 * ref_vs_con_pred(turnout) /
  (lab_vs_con_pred(turnout) + con_vs_con_pred(turnout) + ref_vs_con_pred(turnout))
```

Note the Conservative predictions, since it is the base category with intercept and slope of zero:

```{r}
con_vs_con_pred(seq(0, 100, 10))
```

(I wanted to follow the recipe rather than just add a constant.)

```{r dpi=300}
plot_votes +
  geom_function(
    fun = lab_pred,
    colour = "#d50000",
    linewidth = 1,
    linetype = "dashed"
  ) +
  geom_function(
    fun = con_pred,
    colour = "#0087dc",
    linewidth = 1,
    linetype = "dashed"
  ) +
  geom_function(
    fun = ref_pred,
    colour = "#12b6cf",
    linewidth = 1,
    linetype = "dashed"
  ) +
  labs(title = "UK general election 2024 – colm model predictions",
       caption = "Percentage votes are conditional on voting Tory, Labour, or Reform.\nDashed curves are colm model predictions; solid curves are loess.") +
  geom_smooth(se = FALSE,
              method = "loess",
              formula = y ~ x)
```

The loess curve looks more sigmoid-shaped than the colm fit.


### Try again with percentages

If I've understood the model correctly, then using the percentages as outcomes, rather than counts, should give the same model coefficients and standard errors:

```{r}
for_analy_percs <- perc |>
  select(-Votes) |>
  pivot_wider(names_from = "Party",
              values_from = "Perc")
for_analy_percs
```

```{r}
mod1_perc <- colm(cbind(Con, Lab, RUK) ~ turnout_percentage,
                  ref = 1,
                  data = for_analy_percs)
mod2_perc <- colm(cbind(Con, Lab, RUK) ~ turnout_percentage,
                  ref = 2,
                  data = for_analy_percs)
mod3_perc <- colm(cbind(Con, Lab, RUK) ~ turnout_percentage,
                  ref = 3,
                  data = for_analy_percs)
```

Reference level Con:

```{r}
mod1_count |> short_sum()
mod1_perc  |> short_sum()
```

Reference level Lab:

```{r}
mod2_count |> short_sum()
mod2_perc  |> short_sum()
```

Reference level Reform:

```{r}
mod3_count |> short_sum()
mod3_perc  |> short_sum()
```

And indeed they do.

The fitted values are different, though -- they are on the original scale:

```{r}
mod1_perc$fitted.values |> head()
```

```{r}
mod1_count$fitted.values |> head()
```



## Comparison with multinomial regression

```{r}
library(nnet)
```


```{r}
mn_mod1 <- multinom(cbind(Con, Lab, RUK) ~ turnout_percentage,
                    Hess = TRUE,
                    data = for_analy_counts)
mn_mod1 |> summary()
```

Compare with colm:

```{r}
mod1_count |> short_sum()
```

The estimates are similar. The multinomial regression SEs are much smaller, presumably because it can take advantage of the counts.


Plot predictions:

```{r}
pred_mod <- Vectorize(function(turnout, party) {
  pred_matrix <- predict(mn_mod1,
                         newdat = data.frame(turnout_percentage = turnout),
                         type = "probs") |> as.matrix()
  
  pred_matrix[party, ] |>
    as.vector() * 100
})
```


```{r dpi=300}
plot_votes +
  geom_function(
    fun = \(x) pred_mod(x, "Lab"),
    colour = "#d50000",
    linewidth = 1,
    linetype = "dashed"
  ) +
  geom_function(
    fun = \(x) pred_mod(x, "Con"),
    colour = "#0087dc",
    linewidth = 1,
    linetype = "dashed"
  ) +
  geom_function(
    fun = \(x) pred_mod(x, "RUK"),
    colour = "#12b6cf",
    linewidth = 1,
    linetype = "dashed"
  ) +
  labs(title = "UK general election 2024 – multinomial model predictions",
       caption = "Percentage votes are conditional on voting Tory, Labour, or Reform.\nDashed curves are multinom model predictions; solid curves are loess.") +
  geom_smooth(se = FALSE,
              method = "loess",
              formula = y ~ x)
```

Same issue as for the colm model that the predictions aren't sufficiently s-shaped, which is unsurprising given how similar the coefficients are.

Try lobbing a third degree polynomial at it:


```{r dpi=300}
mn_mod_2 <- multinom(cbind(Con, Lab, RUK) ~ poly(turnout_percentage, 3),
                     Hess = TRUE,
                     data = for_analy_counts)

pred_mod_2 <- Vectorize(function(turnout, party) {
  pred_matrix <- predict(mn_mod_2,
                         newdat = data.frame(turnout_percentage = turnout),
                         type = "probs") |> as.matrix()
  
  pred_matrix[party, ] |>
    as.vector() * 100
})

plot_votes +
  geom_function(
    fun = \(x) pred_mod_2(x, "Lab"),
    colour = "#d50000",
    linewidth = 1,
    linetype = "dashed"
  ) +
  geom_function(
    fun = \(x) pred_mod_2(x, "Con"),
    colour = "#0087dc",
    linewidth = 1,
    linetype = "dashed"
  ) +
  geom_function(
    fun = \(x) pred_mod_2(x, "RUK"),
    colour = "#12b6cf",
    linewidth = 1,
    linetype = "dashed"
  ) +
  labs(title = "UK general election 2024 – multinomial model predictions", caption = "Percentage votes are conditional on voting Tory, Labour, or Reform.\nDashed curves are multinom model predictions; solid curves are loess.") +
  geom_smooth(se = FALSE,
              method = "loess",
              formula = y ~ x)
mn_mod_2
```



## What effect does having a Reform candidate have on the split between Tory/Labour?

They stood most places, so this is going to be tricky...

```{r}
reform_ass <- simp_dat |>
  drop_na(Lab, Con, turnout_percentage) |>
  mutate(reform_stood = 1 - is.na(RUK),
         Lab_perc = 100 * Lab / (Lab + Con))
```


```{r}
table1(~ Lab + Con + RUK + reform_stood + turnout_percentage, data = reform_ass)
```

Where they didn't stand:

```{r paged.print=FALSE}
reform_ass |>
  dplyr::filter(reform_stood == 0) |>
  arrange(-Lab_perc) |>
  select(-c(RUK, reform_stood)) |>
  print(n = Inf)
```


```{r dpi=300}
reform_ass |>
  ggplot(aes(
    colour = factor(reform_stood, labels = c("No", "Yes")),
    x = turnout_percentage,
    y = Lab_perc
  )) +
  geom_point() +
  geom_smooth(method = "loess",
              formula = "y ~ x",
              se = TRUE) +
  labs(x = "Turnout (%)",
       y = "Percentage voting Lab (versus Con)",
       colour = "Reform stood",
       title = "Percentage voting Lab (vs. Con)") +
  ylim(0, NA)
```

Not enough data to have faith in this!


## Turnout and unemployment (as another index of deprivation)

```{r}
unemployment_june_dat <- read_csv("unemployment_benefit_june_2024.csv")
unemployment_june_dat
```

```{r}
summary(unemployment_june_dat)
```



```{r}
vote_unemp <- left_join(simp_dat,
                        unemployment_june_dat |>
                          rename(constituency = "Constituency",
                                 unemp_percent = "Percent") |>
                          select(-Number))
```


```{r dpi = 300}
vote_unemp |>
  ggplot(aes(y = turnout_percentage, x = unemp_percent)) +
  geom_point() +
  geom_smooth(formula = y ~ x, span = 2, se = FALSE) +
  labs(y = "Turnout (%)",
       x = "Claimant rate (%)",
       caption = "Claimant rate is the percentage of the population aged 16–64 who are claiming unemployment related benefits.",
       title = "Turnout as a function of unemployment benefit claimant rates")
```


```{r dpi=300}
left_join(
  perc,
  unemployment_june_dat |>
    rename(constituency = "Constituency", unemp_percent = "Percent") |>
    select(-Number)
) |>
  ggplot(aes(unemp_percent, Perc, colour = Party)) +
  geom_point(size = .7) +
  labs(
    x = "Claimant rate (%)",
    y = "Votes (%)",
    title = "UK general election 2024",
    caption = "Percentage votes are conditional on voting Tory, Labour, or Reform"
  ) +
  scale_color_manual(values = c("#0087dc", "#d50000", "#12b6cf")) +
  geom_smooth(se = FALSE,
              method = "loess",
              formula = y ~ x,
              span = .8)
```



```{r}
mn_tout_unemp <- multinom(cbind(Con, Lab, RUK) ~ turnout_percentage + unemp_percent ,
                    Hess = TRUE,
                    data = vote_unemp)
mn_tout_unemp |> summary()
mn_tout_unemp |> confint()
```


